<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Graph World Model</title>

  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css" integrity="sha512-DTOQO9RWCH3ppGqcWaEA1BIZOC6xxalwEsw9c2QQeAIftl+Vegovlnee1c9QX4TctnWMn13TZye+giMm8e2LwA==" crossorigin="anonymous" referrerpolicy="no-referrer" />

  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Fusing LLM Capabilities with Routing Data</h1>
            <div class="is-size-5 publication-authors">
  <!-- Paper authors -->
<div class="is-size-6 publication-authors">
 <span class="author-block"><b>Tao Feng</b>,</span>
 <span class="author-block"><b>Yexin Wu</b>,</span>
 <span class="author-block"><b>Guanyu Lin</b>,</span>
 <span class="author-block"><b>Jiaxuan You</b></span>
</div>
<div class="is-size-6 publication-authors" style="margin-top: 0.5em;">
 <span class="author-block">University of Illinois Urbana-Champaign</span><br/>
</div>

<div class="is-size-6 publication-authors" style="margin-top: 0.5em;">
  <span class="author-block">{taofeng2, jiaxuan}@illinois.edu</span>
</div>


                  <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2507.10539" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/ulab-uiuc/GWM" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
   

        
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- Teaser video-->
<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <source src="static/videos/excel.mov"
        type="video/mp4">
      </video>

    </div>
  </div>
</section> -->
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            World models (WMs) demonstrate strong capabilities in prediction, generation, and planning tasks. 
            Existing WMs primarily focus on unstructured data while cannot leverage the ubiquitous structured data, often represented as graphs, in the digital world. While multiple graph foundation models have been proposed, they focus on graph learning tasks and cannot extend to diverse multi-modal data and interdisciplinary tasks. 
            To address these challenges, we propose the Graph World Model (GWM), a world model that supports both unstructured and graph-structured states with multi-modal information and represents diverse tasks as actions. The core of a GWM is a generic message-passing algorithm to aggregate structured information, either over a unified multi-modal token space by converting multi-modal data into text (GWM-T) or a unified multi-modal embedding space by modality-specific encoders (GWM-E). 
            Notably, GWM introduces action nodes to support diverse tasks, where action nodes are linked to other nodes via direct reference or similarity computation. Extensive experiments on 6 tasks from diverse domains, including multi-modal generation and matching, recommendation, graph prediction, multi-agent, retrieval-augmented generation, and planning and optimization, show that the same GWM outperforms or matches domain-specific baselines' performance, benefits from multi-hop structures, and demonstrates strong zero-shot/few-shot capabilities on unseen new tasks.
          </p>
        </div>

        <!-- <div class="content">
          <div class=" has-text-centered">
            <img src="static/images/figure2.png" alt="MY ALT TEXT"/>
          </div>
          <b class="subtitle is-size-6">
            Thought-Retriever Framework. (a) Thought retrieval: Upon receiving a user query, Thought-Retriever retrieves top-K data
            chunks from the mixture of external knowledge and thought memory based on embedding similarity; (b) Answer generation: The LLM generates the answer for the user query based on the retrieved data chunks; (c) Thought generation: The LLM further generates thought and its confidence based on the user query and the generated answer; (d) Thought memory update: Meaningless and redundant thoughts are removed and the remaining novel thoughts are used to update the thought memory. 
          </b>
        </div> -->

      </div>
    </div>
  </div>
</section>



<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">1. Multi-modal world state transition can be modeled via graphs.</h2>
        <div class="content">

          <div class="content has-text-justified">
          
            <p> We model the current state as a graph with multi-modal nodes containing image, table, and text data. Actions are represented as action nodes that query the state, categorized into intended actions (node, edge, graph levels) and unintended actions (using similarity computation). The transition function updates states at three levels: nodes, edges, and graphs. </p>
            
          </div>

          <div class=" has-text-centered">
            <img src="static/images/1.png" alt="MY ALT TEXT"/>
          </div>
          <b class="subtitle is-size-6">
          </b>
        </div>

      
      </div>
    </div>
  </div>
</section>

<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">2. Instantiations of GWM.</h2>
        <div class="content">
          <div class=" has-text-centered">
            <img src="static/images/2.png" alt="MY ALT TEXT"/>
          </div>
<p>
  Representative instantiations that can be unified into a GWM from three aspects: world prediction, world generation, and world optimization. Specifically, GWM covers six scenarios: multi-modal generation and matching, recommendation systems, graph prediction, multi-agent collaboration, retrieval-augmented generation, and planning and optimization. It represents different entities and their interactions as graph nodes and edges, enabling unified modeling across these tasks.

</p>



        </div>

      </div>
    </div>
  </div>
</section>

  <section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">3. Overall framework.</h2>
        <div class="content">
          <div class=" has-text-centered">
            <img src="static/images/3.png" alt="MY ALT TEXT"/>
          </div>
<p>
  The core of a GWM is a message-passing algorithm that aggregates structured info, either in a unified token space (GWM-T) or embedding space (GWM-E) via modality-specific encoders.


</p>



        </div>

      </div>
    </div>
  </div>
</section>

<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">4. Experiments</h2>
        <h2 class="title is-4">4.1 A single GWM matches the performance of
domain-specific methods across multiple tasks</h2>
        <div class="content has-text-justified">
          <p>
            We have the following observations: (1) Strong generalization: A single GWM achieves SOTA results in multi-modal generation, multi-agent collaboration, RAG, and planning/optimization, while performing comparably to domain-specific baselines in other tasks.
(2) Efficient long-context processing: GWM with 2k context length outperforms LLM models with 128k context in RAG tasks, demonstrating superior long-text understanding and reasoning capabilities.
(3) Embedding efficiency: GWM-E outperforms GWM-T in 5 out of 7 tasks while using approximately 5-10 times fewer tokens, proving the effectiveness of embedding-based message passing.

          </p>
        </div>
        <div class="content">
          <div class=" has-text-centered">
            <img src="static/images/4.png"  alt="MY ALT TEXT"/>
          </div>
  
        </div>
      

        <h2 class="title is-4">4.2 GWM benefits from multi-hop graphs</h2>
        <div class="content has-text-justified">
          <p>
             Multi-hop graphs consistently improve GWM-E performance across all tasks with at least 20% relative gain on graph-related tasks. However, increasing hop numbers doesn't always yield better results due to over-smoothing and redundant information introduction.
          </p>
        </div>
        
        <div class="content">
          <div class=" has-text-centered">
            <img src="static/images/5.png"  alt="MY ALT TEXT"/>
          </div>
  
        </div>

<h2 class="title is-4">4.3 GWM boosts zero-shot/few-shot performance</h2>
<div class="content has-text-justified">
  <p>
    The experiments demonstrate that GWM exhibits strong zero-shot and few-shot capabilities. GWM can effectively adapt to new tasks with minimal domain-specific training data, and its zero-shot performance on RAG tasks even surpasses single-task training results, indicating excellent generalization ability that particularly benefits tasks with limited training data.
  </p>
</div>

<div class="content">
  <div class="has-text-centered">
    <img src="static/images/6.png" alt="Ablation Study Results"/>
  </div>
</div>

      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Image carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        Your image here
        <img src="static/images/carousel1.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          First image description.
        </h2>
      </div>
      <div class="item">
        Your image here
        <img src="static/images/carousel2.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Second image description.
        </h2>
      </div>
      <div class="item">
        Your image here
        <img src="static/images/carousel3.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
         Third image description.
       </h2>
     </div>
     <div class="item">
       Your image here
      <img src="static/images/carousel4.jpg" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered">
        Fourth image description.
      </h2>
    </div>
  </div>
</div>
</div>
</section> -->
<!-- End image carousel -->




<!-- Youtube video -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
       Paper video.
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            Youtube embed code here
            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End youtube video -->


<!-- Video carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
            
            <source src="static/videos/carousel1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%">
            
            <source src="static/videos/carousel2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\
            
            <source src="static/videos/carousel3.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End video carousel -->






<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->

<!-- <section class="section">
  <div class="container is-max-desktop content">
        <h2 class="title">Community</h2>
        <div class="content has-text-justified">
          <p>
            Join our community to connect with other agent enthusiasts, share your tools and demos, and collaborate on exciting initiatives. You can find us on <a href="https://join.slack.com/t/slack-ped8294/shared_invite/zt-2cqebow90-soac9UFKGZ2RcUy8PqjZrA" target="_blank" >Slack</a>.
          </p>
       
      </div>
  </div>
</section> -->

<!--BibTeX citation -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{fenggraph,
  title={Graph World Model},
  author={Feng, Tao and Wu, Yexin and Lin, Guanyu and You, Jiaxuan},
  booktitle={Forty-second International Conference on Machine Learning}
}</code></pre>
  </div>
</section>
<!--End BibTeX citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
